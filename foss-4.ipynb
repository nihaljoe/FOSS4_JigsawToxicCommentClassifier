{"cells":[{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"cell_type":"code","source":"import numpy as np \nimport pandas as pd \nfrom tqdm import tqdm\nfrom sklearn.model_selection import train_test_split\nimport tensorflow as tf\nfrom keras.models import Sequential\nfrom keras.layers.recurrent import LSTM, GRU,SimpleRNN\nfrom keras.layers.core import Dense, Activation, Dropout\nfrom keras.layers.embeddings import Embedding\nfrom keras.layers.normalization import BatchNormalization\nfrom keras.utils import np_utils\nfrom sklearn import preprocessing, decomposition, model_selection, metrics, pipeline\nfrom keras.layers import GlobalMaxPooling1D, Conv1D, MaxPooling1D, Flatten, Bidirectional, SpatialDropout1D\nfrom keras.preprocessing import sequence, text\nfrom keras.callbacks import EarlyStopping\n\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\nfrom plotly import graph_objs as go\nimport plotly.express as px\nimport plotly.figure_factory as ff","execution_count":2,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Detect hardware, return appropriate distribution strategy\ntry:\n    # TPU detection. No parameters necessary if TPU_NAME environment variable is\n    # set: this is always the case on Kaggle.\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n    print('Running on TPU ', tpu.master())\nexcept ValueError:\n    tpu = None\n\nif tpu:\n    tf.config.experimental_connect_to_cluster(tpu)\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n    strategy = tf.distribute.experimental.TPUStrategy(tpu)\nelse:\n    # Default distribution strategy in Tensorflow. Works on CPU and single GPU.\n    strategy = tf.distribute.get_strategy()\n\nprint(\"REPLICAS: \", strategy.num_replicas_in_sync)","execution_count":3,"outputs":[{"output_type":"stream","text":"Running on TPU  grpc://10.0.0.2:8470\nREPLICAS:  8\n","name":"stdout"}]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"train = pd.read_csv('/kaggle/input/jigsaw-multilingual-toxic-comment-classification/jigsaw-toxic-comment-train.csv')\nvalidation = pd.read_csv('/kaggle/input/jigsaw-multilingual-toxic-comment-classification/validation.csv')\ntest = pd.read_csv('/kaggle/input/jigsaw-multilingual-toxic-comment-classification/test.csv')","execution_count":4,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.drop(['severe_toxic','obscene','threat','insult','identity_hate'],axis=1,inplace=True)","execution_count":5,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = train.loc[:12000,:]\ntrain.shape","execution_count":6,"outputs":[{"output_type":"execute_result","execution_count":6,"data":{"text/plain":"(12001, 3)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['comment_text'].apply(lambda x:len(str(x).split())).max()","execution_count":7,"outputs":[{"output_type":"execute_result","execution_count":7,"data":{"text/plain":"1403"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"def roc_auc(predictions,target):\n    '''\n    This methods returns the AUC Score when given the Predictions\n    and Labels\n    '''\n    \n    fpr, tpr, thresholds = metrics.roc_curve(target, predictions)\n    roc_auc = metrics.auc(fpr, tpr)\n    return roc_auc","execution_count":8,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"xtrain, xvalid, ytrain, yvalid = train_test_split(train.comment_text.values, train.toxic.values, \n                                                  stratify=train.toxic.values, \n                                                  random_state=42, \n                                                  test_size=0.2, shuffle=True)","execution_count":9,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\ntoken = text.Tokenizer(num_words=None)\nmax_len = 1500\n\ntoken.fit_on_texts(list(xtrain) + list(xvalid))\nxtrain_seq = token.texts_to_sequences(xtrain)\nxvalid_seq = token.texts_to_sequences(xvalid)\n\n#zero pad the sequences\nxtrain_pad = sequence.pad_sequences(xtrain_seq, maxlen=max_len)\nxvalid_pad = sequence.pad_sequences(xvalid_seq, maxlen=max_len)\n\nword_index = token.word_index","execution_count":10,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nwith strategy.scope():\n    # A simpleRNN without any pretrained embeddings and one dense layer\n    model = Sequential()\n    model.add(Embedding(len(word_index) + 1,\n                     300,\n                     input_length=max_len))\n    model.add(SimpleRNN(150))\n    model.add(Dense(1, activation='sigmoid'))\n    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n    \nmodel.summary()","execution_count":69,"outputs":[{"output_type":"stream","text":"Model: \"sequential_15\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nembedding_14 (Embedding)     (None, 1500, 300)         13049100  \n_________________________________________________________________\nsimple_rnn_11 (SimpleRNN)    (None, 150)               67650     \n_________________________________________________________________\ndense_14 (Dense)             (None, 1)                 151       \n=================================================================\nTotal params: 13,116,901\nTrainable params: 13,116,901\nNon-trainable params: 0\n_________________________________________________________________\nCPU times: user 201 ms, sys: 34.7 ms, total: 235 ms\nWall time: 234 ms\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.fit(xtrain_pad, ytrain, epochs=5, batch_size=16*strategy.num_replicas_in_sync) #Multiplying by Strategy to run on TPU's","execution_count":70,"outputs":[{"output_type":"stream","text":"Epoch 1/5\n75/75 [==============================] - 3s 45ms/step - accuracy: 0.9011 - loss: 0.3069\nEpoch 2/5\n75/75 [==============================] - 3s 45ms/step - accuracy: 0.9161 - loss: 0.2180\nEpoch 3/5\n75/75 [==============================] - 3s 46ms/step - accuracy: 0.9664 - loss: 0.0979\nEpoch 4/5\n75/75 [==============================] - 3s 46ms/step - accuracy: 0.9919 - loss: 0.0298\nEpoch 5/5\n75/75 [==============================] - 3s 45ms/step - accuracy: 0.9985 - loss: 0.0088\n","name":"stdout"},{"output_type":"execute_result","execution_count":70,"data":{"text/plain":"<tensorflow.python.keras.callbacks.History at 0x7f99e0b782d0>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"scores = model.predict(xvalid_pad)\nprint(\"Auc: %.2f%%\" % (roc_auc(scores[:2401],yvalid)))","execution_count":71,"outputs":[{"output_type":"stream","text":"Auc: 0.88%\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"scores_model = []\nscores_model.append({'Model': 'SimpleRNN','AUC_Score': roc_auc(scores[:2401],yvalid)})\nscores_model[0]={'Model': 'SimpleRNN','AUC_Score': roc_auc(scores[:2401],yvalid)}","execution_count":72,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"xtrain_seq[:1]","execution_count":42,"outputs":[{"output_type":"execute_result","execution_count":42,"data":{"text/plain":"[[664,\n  65,\n  7,\n  19,\n  2262,\n  14102,\n  5,\n  2262,\n  20439,\n  6071,\n  4,\n  71,\n  32,\n  20440,\n  6620,\n  39,\n  6,\n  664,\n  65,\n  11,\n  8,\n  20441,\n  1502,\n  38,\n  6072]]"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# load the GloVe vectors in a dictionary:\n\nembeddings_index = {}\nf = open('/kaggle/input/glove840b300dtxt/glove.840B.300d.txt','r',encoding='utf-8')\nfor line in tqdm(f):\n    values = line.split(' ')\n    word = values[0]\n    coefs = np.asarray([float(val) for val in values[1:]])\n    embeddings_index[word] = coefs\nf.close()\n\nprint('Found %s word vectors.' % len(embeddings_index))","execution_count":43,"outputs":[{"output_type":"stream","text":"2196018it [05:57, 6137.13it/s]","name":"stderr"},{"output_type":"stream","text":"Found 2196017 word vectors.\n","name":"stdout"},{"output_type":"stream","text":"\n","name":"stderr"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# create an embedding matrix for the words we have in the dataset\nembedding_matrix = np.zeros((len(word_index) + 1, 300))\nfor word, i in tqdm(word_index.items()):\n    embedding_vector = embeddings_index.get(word)\n    if embedding_vector is not None:\n        embedding_matrix[i] = embedding_vector","execution_count":44,"outputs":[{"output_type":"stream","text":"100%|██████████| 43496/43496 [00:00<00:00, 134102.00it/s]\n","name":"stderr"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nwith strategy.scope():\n    \n    # A simple LSTM with glove embeddings and one dense layer\n    model = Sequential()\n    model.add(Embedding(len(word_index) + 1,\n                     300,\n                     weights=[embedding_matrix],\n                     input_length=max_len,\n                     trainable=False))\n\n    model.add(LSTM(150, dropout=0.25, recurrent_dropout=0.25))\n    model.add(Dense(1, activation='sigmoid'))\n    model.compile(loss='binary_crossentropy', optimizer='adam',metrics=['accuracy'])\n    \nmodel.summary()","execution_count":45,"outputs":[{"output_type":"stream","text":"Model: \"sequential_10\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nembedding_9 (Embedding)      (None, 1500, 300)         13049100  \n_________________________________________________________________\nlstm (LSTM)                  (None, 150)               270600    \n_________________________________________________________________\ndense_9 (Dense)              (None, 1)                 151       \n=================================================================\nTotal params: 13,319,851\nTrainable params: 270,751\nNon-trainable params: 13,049,100\n_________________________________________________________________\nCPU times: user 790 ms, sys: 1.05 s, total: 1.84 s\nWall time: 2.79 s\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.fit(xtrain_pad, ytrain, epochs=5, batch_size=32*strategy.num_replicas_in_sync)","execution_count":46,"outputs":[{"output_type":"stream","text":"Epoch 1/5\n38/38 [==============================] - 6s 146ms/step - accuracy: 0.9137 - loss: 0.2675\nEpoch 2/5\n38/38 [==============================] - 4s 109ms/step - accuracy: 0.9443 - loss: 0.1570\nEpoch 3/5\n38/38 [==============================] - 4s 110ms/step - accuracy: 0.9493 - loss: 0.1364\nEpoch 4/5\n38/38 [==============================] - 4s 109ms/step - accuracy: 0.9550 - loss: 0.1237\nEpoch 5/5\n38/38 [==============================] - 4s 110ms/step - accuracy: 0.9585 - loss: 0.1158\n","name":"stdout"},{"output_type":"execute_result","execution_count":46,"data":{"text/plain":"<tensorflow.python.keras.callbacks.History at 0x7f99e3cbf090>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"scores = model.predict(xvalid_pad)\nprint(\"Auc: %.2f%%\" % (roc_auc(scores[:2401],yvalid)))","execution_count":47,"outputs":[{"output_type":"stream","text":"Auc: 0.97%\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"scores_model.append({'Model': 'LSTM','AUC_Score': roc_auc(scores[:2401],yvalid)})","execution_count":49,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nwith strategy.scope():\n    # GRU with glove embeddings and two dense layers\n     model = Sequential()\n     model.add(Embedding(len(word_index) + 1,\n                     300,\n                     weights=[embedding_matrix],\n                     input_length=max_len,\n                     trainable=False))\n     model.add(SpatialDropout1D(0.3))\n     model.add(GRU(300))\n     model.add(Dense(1, activation='sigmoid'))\n\n     model.compile(loss='binary_crossentropy', optimizer='adam',metrics=['accuracy'])   \n    \nmodel.summary()","execution_count":54,"outputs":[{"output_type":"stream","text":"Model: \"sequential_12\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nembedding_11 (Embedding)     (None, 1500, 300)         13049100  \n_________________________________________________________________\nspatial_dropout1d_1 (Spatial (None, 1500, 300)         0         \n_________________________________________________________________\ngru_1 (GRU)                  (None, 300)               541800    \n_________________________________________________________________\ndense_11 (Dense)             (None, 1)                 301       \n=================================================================\nTotal params: 13,591,201\nTrainable params: 542,101\nNon-trainable params: 13,049,100\n_________________________________________________________________\nCPU times: user 581 ms, sys: 867 ms, total: 1.45 s\nWall time: 3.09 s\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.fit(xtrain_pad, ytrain, epochs=5, batch_size=64*strategy.num_replicas_in_sync)","execution_count":55,"outputs":[{"output_type":"stream","text":"Epoch 1/5\n19/19 [==============================] - 4s 224ms/step - accuracy: 0.8805 - loss: 0.3355\nEpoch 2/5\n19/19 [==============================] - 2s 107ms/step - accuracy: 0.9304 - loss: 0.2136\nEpoch 3/5\n19/19 [==============================] - 2s 107ms/step - accuracy: 0.9450 - loss: 0.1603\nEpoch 4/5\n19/19 [==============================] - 2s 107ms/step - accuracy: 0.9518 - loss: 0.1312\nEpoch 5/5\n19/19 [==============================] - 2s 107ms/step - accuracy: 0.9550 - loss: 0.1189\n","name":"stdout"},{"output_type":"execute_result","execution_count":55,"data":{"text/plain":"<tensorflow.python.keras.callbacks.History at 0x7f99e285c8d0>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"scores = model.predict(xvalid_pad)\nprint(\"Auc: %.2f%%\" % (roc_auc(scores[:2401],yvalid)))","execution_count":56,"outputs":[{"output_type":"stream","text":"Auc: 0.98%\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"scores_model.append({'Model': 'GRU','AUC_Score': roc_auc(scores[:2401],yvalid)})","execution_count":53,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"scores_model","execution_count":73,"outputs":[{"output_type":"execute_result","execution_count":73,"data":{"text/plain":"[{'Model': 'SimpleRNN', 'AUC_Score': 0.8822406575102635},\n {'Model': 'LSTM', 'AUC_Score': 0.9744598762305015},\n {'Model': 'GRU', 'AUC_Score': 0.9757486352528277}]"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nwith strategy.scope():\n    # A simple bidirectional LSTM with glove embeddings and one dense layer\n    model = Sequential()\n    model.add(Embedding(len(word_index) + 1,\n                     300,\n                     weights=[embedding_matrix],\n                     input_length=max_len,\n                     trainable=False))\n    model.add(Bidirectional(LSTM(200, dropout=0.25, recurrent_dropout=0.25)))\n\n    model.add(Dense(1,activation='sigmoid'))\n    model.compile(loss='binary_crossentropy', optimizer='adam',metrics=['accuracy'])\n    \n    \nmodel.summary()","execution_count":78,"outputs":[{"output_type":"stream","text":"Model: \"sequential_18\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nembedding_17 (Embedding)     (None, 1500, 300)         13049100  \n_________________________________________________________________\nbidirectional_2 (Bidirection (None, 400)               801600    \n_________________________________________________________________\ndense_17 (Dense)             (None, 1)                 401       \n=================================================================\nTotal params: 13,851,101\nTrainable params: 802,001\nNon-trainable params: 13,049,100\n_________________________________________________________________\nCPU times: user 1.18 s, sys: 1.05 s, total: 2.23 s\nWall time: 2.19 s\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.fit(xtrain_pad, ytrain, epochs=5, batch_size=32*strategy.num_replicas_in_sync)","execution_count":79,"outputs":[{"output_type":"stream","text":"Epoch 1/5\n38/38 [==============================] - 11s 284ms/step - accuracy: 0.9051 - loss: 0.2821\nEpoch 2/5\n38/38 [==============================] - 9s 233ms/step - accuracy: 0.9422 - loss: 0.1616\nEpoch 3/5\n38/38 [==============================] - 9s 233ms/step - accuracy: 0.9509 - loss: 0.1399\nEpoch 4/5\n38/38 [==============================] - 9s 233ms/step - accuracy: 0.9538 - loss: 0.1292\nEpoch 5/5\n38/38 [==============================] - 9s 233ms/step - accuracy: 0.9505 - loss: 0.1333\n","name":"stdout"},{"output_type":"execute_result","execution_count":79,"data":{"text/plain":"<tensorflow.python.keras.callbacks.History at 0x7f99de640d90>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"scores = model.predict(xvalid_pad)\nprint(\"Auc: %.2f%%\" % (roc_auc(scores[:2401],yvalid)))","execution_count":80,"outputs":[{"output_type":"stream","text":"Auc: 0.97%\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"scores_model.append({'Model': 'Bi-directional LSTM','AUC_Score': roc_auc(scores[:2401],yvalid)})","execution_count":81,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Visualization of Results obtained from various Deep learning models\nresults = pd.DataFrame(scores_model).sort_values(by='AUC_Score',ascending=False)\nresults.style.background_gradient(cmap='Blues')","execution_count":82,"outputs":[{"output_type":"execute_result","execution_count":82,"data":{"text/plain":"<pandas.io.formats.style.Styler at 0x7f99ddfa0610>","text/html":"<style  type=\"text/css\" >\n    #T_84ce2d28_0646_11eb_b693_0242ac130202row0_col1 {\n            background-color:  #08306b;\n            color:  #f1f1f1;\n        }    #T_84ce2d28_0646_11eb_b693_0242ac130202row1_col1 {\n            background-color:  #083370;\n            color:  #f1f1f1;\n        }    #T_84ce2d28_0646_11eb_b693_0242ac130202row2_col1 {\n            background-color:  #084990;\n            color:  #f1f1f1;\n        }    #T_84ce2d28_0646_11eb_b693_0242ac130202row3_col1 {\n            background-color:  #f7fbff;\n            color:  #000000;\n        }</style><table id=\"T_84ce2d28_0646_11eb_b693_0242ac130202\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >Model</th>        <th class=\"col_heading level0 col1\" >AUC_Score</th>    </tr></thead><tbody>\n                <tr>\n                        <th id=\"T_84ce2d28_0646_11eb_b693_0242ac130202level0_row0\" class=\"row_heading level0 row0\" >2</th>\n                        <td id=\"T_84ce2d28_0646_11eb_b693_0242ac130202row0_col0\" class=\"data row0 col0\" >GRU</td>\n                        <td id=\"T_84ce2d28_0646_11eb_b693_0242ac130202row0_col1\" class=\"data row0 col1\" >0.975749</td>\n            </tr>\n            <tr>\n                        <th id=\"T_84ce2d28_0646_11eb_b693_0242ac130202level0_row1\" class=\"row_heading level0 row1\" >1</th>\n                        <td id=\"T_84ce2d28_0646_11eb_b693_0242ac130202row1_col0\" class=\"data row1 col0\" >LSTM</td>\n                        <td id=\"T_84ce2d28_0646_11eb_b693_0242ac130202row1_col1\" class=\"data row1 col1\" >0.974460</td>\n            </tr>\n            <tr>\n                        <th id=\"T_84ce2d28_0646_11eb_b693_0242ac130202level0_row2\" class=\"row_heading level0 row2\" >3</th>\n                        <td id=\"T_84ce2d28_0646_11eb_b693_0242ac130202row2_col0\" class=\"data row2 col0\" >Bi-directional LSTM</td>\n                        <td id=\"T_84ce2d28_0646_11eb_b693_0242ac130202row2_col1\" class=\"data row2 col1\" >0.966816</td>\n            </tr>\n            <tr>\n                        <th id=\"T_84ce2d28_0646_11eb_b693_0242ac130202level0_row3\" class=\"row_heading level0 row3\" >0</th>\n                        <td id=\"T_84ce2d28_0646_11eb_b693_0242ac130202row3_col0\" class=\"data row3 col0\" >SimpleRNN</td>\n                        <td id=\"T_84ce2d28_0646_11eb_b693_0242ac130202row3_col1\" class=\"data row3 col1\" >0.882241</td>\n            </tr>\n    </tbody></table>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = go.Figure(go.Funnelarea(\n    text =results.Model,\n    values = results.AUC_Score,\n    title = {\"position\": \"top center\", \"text\": \"Funnel-Chart of Sentiment Distribution\"}\n    ))\nfig.show()","execution_count":83,"outputs":[{"output_type":"display_data","data":{"text/html":"        <script type=\"text/javascript\">\n        window.PlotlyConfig = {MathJaxConfig: 'local'};\n        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n        if (typeof require !== 'undefined') {\n        require.undef(\"plotly\");\n        requirejs.config({\n            paths: {\n                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n            }\n        });\n        require(['plotly'], function(Plotly) {\n            window._Plotly = Plotly;\n        });\n        }\n        </script>\n        "},"metadata":{}},{"output_type":"display_data","data":{"text/html":"<div>\n        \n        \n            <div id=\"6bcc9f32-cca1-4d5b-ac13-da53cbfac2d0\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>\n            <script type=\"text/javascript\">\n                require([\"plotly\"], function(Plotly) {\n                    window.PLOTLYENV=window.PLOTLYENV || {};\n                    \n                if (document.getElementById(\"6bcc9f32-cca1-4d5b-ac13-da53cbfac2d0\")) {\n                    Plotly.newPlot(\n                        '6bcc9f32-cca1-4d5b-ac13-da53cbfac2d0',\n                        [{\"text\": [\"GRU\", \"LSTM\", \"Bi-directional LSTM\", \"SimpleRNN\"], \"title\": {\"position\": \"top center\", \"text\": \"Funnel-Chart of Sentiment Distribution\"}, \"type\": \"funnelarea\", \"values\": [0.9757486352528277, 0.9744598762305015, 0.9668164815257609, 0.8822406575102635]}],\n                        {\"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}},\n                        {\"responsive\": true}\n                    ).then(function(){\n                            \nvar gd = document.getElementById('6bcc9f32-cca1-4d5b-ac13-da53cbfac2d0');\nvar x = new MutationObserver(function (mutations, observer) {{\n        var display = window.getComputedStyle(gd).display;\n        if (!display || display === 'none') {{\n            console.log([gd, 'removed!']);\n            Plotly.purge(gd);\n            observer.disconnect();\n        }}\n}});\n\n// Listen for the removal of the full notebook cells\nvar notebookContainer = gd.closest('#notebook-container');\nif (notebookContainer) {{\n    x.observe(notebookContainer, {childList: true});\n}}\n\n// Listen for the clearing of the current output cell\nvar outputEl = gd.closest('.output');\nif (outputEl) {{\n    x.observe(outputEl, {childList: true});\n}}\n\n                        })\n                };\n                });\n            </script>\n        </div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Loading Dependencies\nimport os\nimport tensorflow as tf\nfrom tensorflow.keras.layers import Dense, Input\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.callbacks import ModelCheckpoint\nfrom kaggle_datasets import KaggleDatasets\nimport transformers\n\nfrom tokenizers import BertWordPieceTokenizer","execution_count":84,"outputs":[{"output_type":"stream","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m W&B installed but not logged in.  Run `wandb login` or set the WANDB_API_KEY env variable.\n","name":"stderr"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# LOADING THE DATA\n\ntrain1 = pd.read_csv(\"/kaggle/input/jigsaw-multilingual-toxic-comment-classification/jigsaw-toxic-comment-train.csv\")\nvalid = pd.read_csv('/kaggle/input/jigsaw-multilingual-toxic-comment-classification/validation.csv')\ntest = pd.read_csv('/kaggle/input/jigsaw-multilingual-toxic-comment-classification/test.csv')\nsub = pd.read_csv('/kaggle/input/jigsaw-multilingual-toxic-comment-classification/sample_submission.csv')","execution_count":85,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Encoder FOr DATA for understanding waht encode batch does read documentation of hugging face tokenizer :\nhttps://huggingface.co/transformers/main_classes/tokenizer.html here"},{"metadata":{"trusted":true},"cell_type":"code","source":"def fast_encode(texts, tokenizer, chunk_size=256, maxlen=512):\n    \"\"\"\n    Encoder for encoding the text into sequence of integers for BERT Input\n    \"\"\"\n    tokenizer.enable_truncation(max_length=maxlen)\n    tokenizer.enable_padding(max_length=maxlen)\n    all_ids = []\n    \n    for i in tqdm(range(0, len(texts), chunk_size)):\n        text_chunk = texts[i:i+chunk_size].tolist()\n        encs = tokenizer.encode_batch(text_chunk)\n        all_ids.extend([enc.ids for enc in encs])\n    \n    return np.array(all_ids)","execution_count":86,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#IMP DATA FOR CONFIG\n\nAUTO = tf.data.experimental.AUTOTUNE\n\n\n# Configuration\nEPOCHS = 6\nBATCH_SIZE = 18 * strategy.num_replicas_in_sync\nMAX_LEN = 192","execution_count":87,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# First load the real tokenizer\ntokenizer = transformers.DistilBertTokenizer.from_pretrained('distilbert-base-multilingual-cased')\n# Save the loaded tokenizer locally\ntokenizer.save_pretrained('.')\n# Reload it with the huggingface tokenizers library\nfast_tokenizer = BertWordPieceTokenizer('vocab.txt', lowercase=False)\nfast_tokenizer","execution_count":88,"outputs":[{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=0.0, description='Downloading', max=995526.0, style=ProgressStyle(descripti…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e9ad5bd24aec419793ab2aa0b5e39a79"}},"metadata":{}},{"output_type":"stream","text":"\n","name":"stdout"},{"output_type":"execute_result","execution_count":88,"data":{"text/plain":"Tokenizer(vocabulary_size=119547, model=BertWordPiece, unk_token=[UNK], sep_token=[SEP], cls_token=[CLS], pad_token=[PAD], mask_token=[MASK], clean_text=True, handle_chinese_chars=True, strip_accents=True, lowercase=False, wordpieces_prefix=##)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train = fast_encode(train1.comment_text.astype(str), fast_tokenizer, maxlen=MAX_LEN)\nx_valid = fast_encode(valid.comment_text.astype(str), fast_tokenizer, maxlen=MAX_LEN)\nx_test = fast_encode(test.content.astype(str), fast_tokenizer, maxlen=MAX_LEN)\n\ny_train = train1.toxic.values\ny_valid = valid.toxic.values","execution_count":89,"outputs":[{"output_type":"stream","text":"100%|██████████| 874/874 [00:35<00:00, 24.55it/s]\n100%|██████████| 32/32 [00:01<00:00, 26.06it/s]\n100%|██████████| 250/250 [00:10<00:00, 23.36it/s]\n","name":"stderr"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_dataset = (\n    tf.data.Dataset\n    .from_tensor_slices((x_train, y_train))\n    .repeat()\n    .shuffle(2048)\n    .batch(BATCH_SIZE)\n    .prefetch(AUTO)\n)\n\nvalid_dataset = (\n    tf.data.Dataset\n    .from_tensor_slices((x_valid, y_valid))\n    .batch(BATCH_SIZE)\n    .cache()\n    .prefetch(AUTO)\n)\n\ntest_dataset = (\n    tf.data.Dataset\n    .from_tensor_slices(x_test)\n    .batch(BATCH_SIZE)\n)","execution_count":90,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def build_model(transformer, max_len=512):\n    \"\"\"\n    function for training the BERT model\n    \"\"\"\n    input_word_ids = Input(shape=(max_len,), dtype=tf.int32, name=\"input_word_ids\")\n    sequence_output = transformer(input_word_ids)[0]\n    cls_token = sequence_output[:, 0, :]\n    out = Dense(1, activation='sigmoid')(cls_token)\n    \n    model = Model(inputs=input_word_ids, outputs=out)\n    model.compile(Adam(lr=1e-5), loss='binary_crossentropy', metrics=['accuracy'])\n    \n    return model","execution_count":48,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nwith strategy.scope():\n    transformer_layer = (\n        transformers.TFDistilBertModel\n        .from_pretrained('distilbert-base-multilingual-cased')\n    )\n    model = build_model(transformer_layer, max_len=MAX_LEN)\nmodel.summary()","execution_count":49,"outputs":[{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=0.0, description='Downloading', max=466.0, style=ProgressStyle(description_…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2a35ec838d8d4ef4b5ae1ccd1bc0fb2d"}},"metadata":{}},{"output_type":"stream","text":"\n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=0.0, description='Downloading', max=910749124.0, style=ProgressStyle(descri…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b6c39d6cad454cada73ebd56a4caeb0e"}},"metadata":{}},{"output_type":"stream","text":"\nModel: \"model\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ninput_word_ids (InputLayer)  [(None, 192)]             0         \n_________________________________________________________________\ntf_distil_bert_model (TFDist ((None, 192, 768),)       134734080 \n_________________________________________________________________\ntf_op_layer_strided_slice (T [(None, 768)]             0         \n_________________________________________________________________\ndense_4 (Dense)              (None, 1)                 769       \n=================================================================\nTotal params: 134,734,849\nTrainable params: 134,734,849\nNon-trainable params: 0\n_________________________________________________________________\nCPU times: user 33.4 s, sys: 11.3 s, total: 44.7 s\nWall time: 51.5 s\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"n_steps = x_train.shape[0] // BATCH_SIZE\ntrain_history = model.fit(\n    train_dataset,\n    steps_per_epoch=n_steps,\n    validation_data=valid_dataset,\n    epochs=EPOCHS\n)","execution_count":50,"outputs":[{"output_type":"stream","text":"Epoch 1/3\n1746/1746 [==============================] - 176s 101ms/step - loss: 0.1320 - accuracy: 0.9484 - val_loss: 0.4166 - val_accuracy: 0.8491\nEpoch 2/3\n1746/1746 [==============================] - 165s 95ms/step - loss: 0.0967 - accuracy: 0.9604 - val_loss: 0.4681 - val_accuracy: 0.8485\nEpoch 3/3\n1746/1746 [==============================] - 165s 95ms/step - loss: 0.0833 - accuracy: 0.9657 - val_loss: 0.6499 - val_accuracy: 0.8480\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"n_steps = x_valid.shape[0] // BATCH_SIZE\ntrain_history_2 = model.fit(\n    valid_dataset.repeat(),\n    steps_per_epoch=n_steps,\n    epochs=EPOCHS*2\n)","execution_count":51,"outputs":[{"output_type":"stream","text":"Epoch 1/6\n62/62 [==============================] - 6s 91ms/step - loss: 0.3367 - accuracy: 0.8595\nEpoch 2/6\n62/62 [==============================] - 6s 91ms/step - loss: 0.2438 - accuracy: 0.8943\nEpoch 3/6\n62/62 [==============================] - 6s 91ms/step - loss: 0.1829 - accuracy: 0.9190\nEpoch 4/6\n62/62 [==============================] - 6s 91ms/step - loss: 0.1261 - accuracy: 0.9449\nEpoch 5/6\n62/62 [==============================] - 6s 91ms/step - loss: 0.0822 - accuracy: 0.9668\nEpoch 6/6\n62/62 [==============================] - 6s 91ms/step - loss: 0.0764 - accuracy: 0.9694\n","name":"stdout"}]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}